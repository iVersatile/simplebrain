# Local LLM Agent - Simplified 
FROM ubuntu:22.04

ENV DEBIAN_FRONTEND=noninteractive

# Create non-root user early
RUN groupadd -r llmuser && useradd -r -g llmuser -u 1000 llmuser

# Install system dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential \
    ca-certificates \
    curl \
    git \
    python3 \
    python3-pip \
    python3-venv \
    python3-dev \
    vim \
    wget \
    cmake \
    libopenblas-dev \
    pkg-config \
    make \
    libcurl4-openssl-dev \
    && rm -rf /var/lib/apt/lists/* \
    && apt-get clean

# Create application directories
RUN mkdir -p /app/workspace /app/models /app/local_agent \
    && chown -R llmuser:llmuser /app

# Create home directory and set up user environment
RUN mkdir -p /home/llmuser \
    && chown -R llmuser:llmuser /home/llmuser

# Switch to non-root user
USER llmuser

# Set up user environment
ENV HOME=/home/llmuser
ENV PATH="$HOME/.local/bin:$PATH"

# Install Python packages
RUN python3 -m pip install --user --upgrade pip setuptools wheel \
    && python3 -m pip install --user --no-cache-dir \
    flask \
    requests

# Create directory structure
RUN mkdir -p /home/llmuser/projects \
    && mkdir -p /home/llmuser/workspace

# Build llama.cpp during Docker build (as root, before switching to llmuser)
WORKDIR /app/workspace
RUN git clone https://github.com/ggerganov/llama.cpp.git \
    && cd llama.cpp \
    && mkdir build \
    && cd build \
    && cmake .. -DCMAKE_BUILD_TYPE=Release \
    && make -j$(nproc) \
    && mkdir -p /app/workspace/projects/llama.cpp \
    && cp /app/workspace/llama.cpp/build/bin/llama-cli /app/workspace/projects/llama.cpp/main \
    && chown -R llmuser:llmuser /app/workspace

WORKDIR /app

# Copy startup script
COPY --chown=llmuser:llmuser startup_simple.sh /app/startup.sh
RUN chmod +x /app/startup.sh

# Security: Use non-root user for runtime
USER llmuser

CMD ["/bin/bash"]